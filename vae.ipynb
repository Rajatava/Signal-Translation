{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPpqN1b2rfD65VExXrwU561",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajatava/Signal-Translation/blob/master/vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4fsvHuWr3Pg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51c74ba0-ccc8-44b9-f9d8-090790a30153"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "print('All changes made in this colab session should now be visible in Drive.')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All changes made in this colab session should now be visible in Drive.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqTBvyUxZxVX",
        "colab_type": "code",
        "outputId": "0892958d-d750-4c85-937b-03198b4de12a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "import numpy as np\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile \n",
        "# Load the Drive helper and mount\n",
        "\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# After executing the cell above, Drive\n",
        "# files will be present in \"/content/drive/My Drive\".\n",
        "!ls \"/content/drive/My Drive\"\n",
        "\n",
        "samplerate, samples = wavfile.read('/content/drive/My Drive/voice.wav')\n",
        "frequencies, times, spectrogram = signal.stft(samples, samplerate)\n",
        "s = spectrogram.shape\n",
        "print(s)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            " 106106213\n",
            " 3rdsem_Bill.PDF\n",
            " 4thsem_Bill.PDF\n",
            " A20006906554.pdf\n",
            " AAMydoc\n",
            " Access.gdoc\n",
            "'Arduino & Python Workshop- 2-09-2018.pdf'\n",
            "'Colab Notebooks'\n",
            " Contacts.vcf\n",
            "'Copy of SetupSTM32CubeMX-5.4.0.linux'\n",
            "'DewarpNet Review.docx'\n",
            "'ENGLISH  PAPER.docx'\n",
            " English.txt\n",
            " file.pdf\n",
            " GeeksforGeeks.rar\n",
            "'Getting started.pdf'\n",
            "'Gmail - A Request for giving NOC on behalf of College as the response of Internship offer letter from Praesus Technologies Private  Ltd.PDF'\n",
            "' guitar.wav'\n",
            "'Internship Letter Official_Rajatava_Mukherje-signed.PDF'\n",
            "'New Doc 2018-11-03 12.26.47.pdf'\n",
            " nonRepeatingCharacter.cpp\n",
            " old_user.py.gdoc\n",
            "'RajatavaMukherjee(2ndyr-A-81)MarDoc_NptelCourse(JOCusingPython).PDF'\n",
            "'Raj on fire.mp4'\n",
            "'Resume (1).PDF'\n",
            "'Resume of Rajatava Mukherjee.docx'\n",
            " Resume.PDF\n",
            " Resume-template.gdoc\n",
            "'Sanet Review github.doc'\n",
            "'Spelling Reform.odt'\n",
            "'Untitled document.gdoc'\n",
            "'Untitled form.gform'\n",
            "'Untitled spreadsheet.gsheet'\n",
            " voice.wav\n",
            "(129, 946)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7NHdcgHYCet",
        "colab_type": "code",
        "outputId": "61dc29c8-05c7-4f97-8d03-4935dbbb56c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0-rc0\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import tensorflow\n",
        "from tensorflow.keras.layers import Lambda, Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.losses import mse, binary_crossentropy\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0-rc0 in /usr/local/lib/python3.6/dist-packages (2.0.0rc0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (3.10.0)\n",
            "Requirement already satisfied: tb-nightly<1.15.0a20190807,>=1.15.0a20190806 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.15.0a20190806)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.34.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.27.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.17.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.1.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.9.0)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.14.0.dev2019080601)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.11.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-rc0) (45.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0-rc0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0-rc0) (1.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0-rc0) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9EbUxEFnwsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reparameterization trick\n",
        "# instead of sampling from Q(z|X), sample epsilon = N(0,I)\n",
        "# z = z_mean + sqrt(var) * epsilon\n",
        "def sampling(args):\n",
        "    \"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
        "\n",
        "    # Arguments\n",
        "        args (tensor): mean and log of variance of Q(z|X)\n",
        "\n",
        "    # Returns\n",
        "        z (tensor): sampled latent vector\n",
        "    \"\"\"\n",
        "\n",
        "    z_mean, z_log_var = args\n",
        "    batch = K.shape(z_mean)[0]\n",
        "    dim = K.int_shape(z_mean)[1]\n",
        "    # by default, random_normal has mean = 0 and std = 1.0\n",
        "    epsilon = K.random_normal(shape=(batch, dim))\n",
        "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "\n",
        "sd = s[0]*s[1]\n",
        "\n",
        "sz = np.reshape(spectrogram,sd)\n",
        "original_dim = sd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMKedmhKuG7m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "693e6edd-101c-4955-8a49-c529c2dc3e40"
      },
      "source": [
        "original_dim"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "122034"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWWjTOg0uDtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# network parameters\n",
        "input_shape = (original_dim,)\n",
        "intermediate_dim = int(sd/50)\n",
        "batch_size = 128\n",
        "latent_dim = int(sd/10)\n",
        "epochs = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTQqG7Jbotj_",
        "colab_type": "code",
        "outputId": "65924125-9f9e-49d7-b111-29755d142969",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(input_shape,intermediate_dim,latent_dim)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(122034,) 2440 12203\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqIDPl0yfuxj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "5f1b97ee-3bce-492e-a3ae-353d256b74a5"
      },
      "source": [
        "# VAE model = encoder + decoder\n",
        "\n",
        "\n",
        "# build encoder model\n",
        "inputs = Input(shape=input_shape, name='encoder_input')\n",
        "x = Dense(intermediate_dim)(inputs)\n",
        "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
        "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
        "\n",
        "# use reparameterization trick to push the sampling out as input\n",
        "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
        "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
        "\n",
        "# instantiate encoder model\n",
        "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
        "encoder.summary()\n",
        "\n",
        "\n",
        "# build decoder model\n",
        "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
        "x = Dense(intermediate_dim)(latent_inputs)\n",
        "outputs = Dense(original_dim)(x)\n",
        "\n",
        "# instantiate decoder model\n",
        "decoder = Model(latent_inputs, outputs, name='decoder')\n",
        "decoder.summary()\n",
        "\n",
        "# instantiate VAE model\n",
        "outputs = decoder(encoder(inputs)[2])\n",
        "vae = Model(inputs, outputs, name='vae_mlp')\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_input (InputLayer)      [(None, 122034)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 2440)         297765400   encoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "z_mean (Dense)                  (None, 12203)        29787523    dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "z_log_var (Dense)               (None, 12203)        29787523    dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "z (Lambda)                      (None, 12203)        0           z_mean[0][0]                     \n",
            "                                                                 z_log_var[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 357,340,446\n",
            "Trainable params: 357,340,446\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "z_sampling (InputLayer)      [(None, 12203)]           0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 2440)              29777760  \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 122034)            297884994 \n",
            "=================================================================\n",
            "Total params: 327,662,754\n",
            "Trainable params: 327,662,754\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVvtAwVIiBEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ9-4QEqiBRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhI7aV1ghJyA",
        "colab_type": "code",
        "outputId": "94c6ceab-a550-471d-f29b-cdfd8318ec78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "models = (encoder, decoder)\n",
        "data = (sz)\n",
        "\n",
        "# VAE loss = mse_loss or xent_loss + kl_loss\n",
        "\n",
        "reconstruction_loss = mse(inputs, outputs)\n",
        "reconstruction_loss = binary_crossentropy(inputs,outputs)\n",
        "\n",
        "reconstruction_loss *= original_dim\n",
        "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
        "kl_loss = K.sum(kl_loss, axis=-1)\n",
        "kl_loss *= -0.5\n",
        "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "vae.add_loss(vae_loss)\n",
        "vae.compile(optimizer='adam')\n",
        "vae.summary()\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
            "Model: \"vae_mlp\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_input (InputLayer)      [(None, 122034)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder (Model)                 [(None, 12203), (Non 357340446   encoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Model)                 (None, 122034)       327662754   encoder[1][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_clip_by_value/Minim [(None, 122034)]     0           decoder[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_clip_by_value (Tens [(None, 122034)]     0           tf_op_layer_clip_by_value/Minimum\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_sub_1 (TensorFlowOp [(None, 122034)]     0           tf_op_layer_clip_by_value[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_add (TensorFlowOpLa [(None, 122034)]     0           tf_op_layer_clip_by_value[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_add_1 (TensorFlowOp [(None, 122034)]     0           tf_op_layer_sub_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 2440)         297765400   encoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Log (TensorFlowOpLa [(None, 122034)]     0           tf_op_layer_add[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_sub (TensorFlowOpLa [(None, 122034)]     0           encoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Log_1 (TensorFlowOp [(None, 122034)]     0           tf_op_layer_add_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "z_log_var (Dense)               (None, 12203)        29787523    dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "z_mean (Dense)                  (None, 12203)        29787523    dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_mul (TensorFlowOpLa [(None, 122034)]     0           encoder_input[0][0]              \n",
            "                                                                 tf_op_layer_Log[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_mul_1 (TensorFlowOp [(None, 122034)]     0           tf_op_layer_sub[0][0]            \n",
            "                                                                 tf_op_layer_Log_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_add_3 (TensorFlowOp [(None, 12203)]      0           z_log_var[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Square (TensorFlowO [(None, 12203)]      0           z_mean[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_add_2 (TensorFlowOp [(None, 122034)]     0           tf_op_layer_mul[0][0]            \n",
            "                                                                 tf_op_layer_mul_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_sub_2 (TensorFlowOp [(None, 12203)]      0           tf_op_layer_add_3[0][0]          \n",
            "                                                                 tf_op_layer_Square[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Exp (TensorFlowOpLa [(None, 12203)]      0           z_log_var[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Neg (TensorFlowOpLa [(None, 122034)]     0           tf_op_layer_add_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_sub_3 (TensorFlowOp [(None, 12203)]      0           tf_op_layer_sub_2[0][0]          \n",
            "                                                                 tf_op_layer_Exp[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mean_1 (TensorFlowO [(None,)]            0           tf_op_layer_Neg[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum (TensorFlowOpLa [(None,)]            0           tf_op_layer_sub_3[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_mul_2 (TensorFlowOp [(None,)]            0           tf_op_layer_Mean_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_mul_3 (TensorFlowOp [(None,)]            0           tf_op_layer_Sum[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_add_4 (TensorFlowOp [(None,)]            0           tf_op_layer_mul_2[0][0]          \n",
            "                                                                 tf_op_layer_mul_3[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mean_2 (TensorFlowO [()]                 0           tf_op_layer_add_4[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_loss (AddLoss)              ()                   0           tf_op_layer_Mean_2[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 685,003,200\n",
            "Trainable params: 685,003,200\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8e79OhskzyE",
        "colab_type": "code",
        "outputId": "39a57b75-f967-4734-8680-d529355ef2bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.transpose(sz).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1704219,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXel9kjth8Gk",
        "colab_type": "code",
        "outputId": "cbd401f6-9232-47f9-c678-67227eec3108",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        }
      },
      "source": [
        "vae.fit(sz,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size)\n",
        "  \n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-f6ba8366ad55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m vae.fit(sz,\n\u001b[1;32m      2\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         batch_size=batch_size)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    594\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    595\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2435\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2436\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2437\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2439\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    571\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    574\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected encoder_input to have shape (122034,) but got array with shape (1,)"
          ]
        }
      ]
    }
  ]
}